name: CI/CD Pipeline

on:
  push:
    branches:
      - test # Trigger on pushes to the 'test' branch
  workflow_dispatch:
    inputs:
      RECREATE_CLUSTER:
        description: 'Recreate EKS cluster on each run'
        type: boolean
        required: false
        default: false

env:
  VENV: myenv
  USER_NAME: rakshitsen
  IMAGE_NAME: better-assess-image
  AWS_REGION: ap-south-1
  CLUSTER_NAME: demo-cluster

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    permissions:
      contents: read
      id-token: write # Required for OIDC authentication with AWS

    steps:
      - name: Checkout SCM
        uses: actions/checkout@v4
        with:
          ref: test # Ensure the 'test' branch is checked out
          token: ${{ secrets.GH_PAT_FOR_CHECKOUT }} # Use a PAT if the repo is private or for more granular control

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x' # Or specify a precise version like '3.9'

      - name: Install dependencies
        run: |
          set -e
          python3 -m venv $VENV
          . $VENV/bin/activate
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Unit test
        run: |
          set -e
          . $VENV/bin/activate
          pytest

      - name: Linting
        run: |
          set -e
          . $VENV/bin/activate
          flake8 .
        continue-on-error: true # Allow the workflow to continue even if linting fails

      - name: Build Docker Image
        run: docker build -t $USER_NAME/$IMAGE_NAME:${{ github.run_number }} .

      - name: Run Security Scan (Trivy)
        run: |
          docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
          aquasec/trivy image $USER_NAME/$IMAGE_NAME:${{ github.run_number }}

      - name: Push Docker Image to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
      - run: docker push $USER_NAME/$IMAGE_NAME:${{ github.run_number }}
        working-directory: . # Ensure this runs in the correct directory if needed

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/GitHubActionsEKSRole # Replace with your IAM Role ARN
          aws-region: ${{ env.AWS_REGION }}

      - name: Install eksctl
        run: |
          curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
          sudo mv /tmp/eksctl /usr/local/bin

      - name: Install kubectl
        uses: azure/setup-kubectl@v3

      - name: Install Helm
        uses: azure/setup-helm@v1

      - name: Create EKS Cluster (Conditional)
        if: github.event.inputs.RECREATE_CLUSTER == 'true'
        run: |
          eksctl create cluster \
            --name ${{ env.CLUSTER_NAME }} \
            --region ${{ env.AWS_REGION }} \
            --nodegroup-name ng1 \
            --node-type t3.medium \
            --nodes 2

          eksctl utils associate-iam-oidc-provider --cluster ${{ env.CLUSTER_NAME }} --approve --region ${{ env.AWS_REGION }}

          curl -O https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.11.0/docs/install/iam_policy.json
          aws iam create-policy \
            --policy-name AWSLoadBalancerControllerIAMPolicy \
            --policy-document file://iam_policy.json

          eksctl create iamserviceaccount \
            --cluster ${{ env.CLUSTER_NAME }} \
            --namespace kube-system \
            --name aws-load-balancer-controller \
            --role-name AmazonEKSLoadBalancerControllerRole \
            --attach-policy-arn arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:policy/AWSLoadBalancerControllerIAMPolicy \
            --approve \
            --region ${{ env.AWS_REGION }}

      - name: Deploy on K8S using EKS
        run: |
          aws eks --region ${{ env.AWS_REGION }} update-kubeconfig --name ${{ env.CLUSTER_NAME }}
          kubectl apply -f namespace.yml
          # Use sed -i.bak for macOS compatibility to avoid issues with inline editing
          sed -i.bak "s|image:latest|${{ env.USER_NAME }}/${{ env.IMAGE_NAME }}:${{ github.run_number }}|g" deployment.yml
          kubectl apply -f deployment.yml
          kubectl apply -f service.yml

      - name: Ingress and Ingress Controller
        run: |
          aws eks --region ${{ env.AWS_REGION }} update-kubeconfig --name ${{ env.CLUSTER_NAME }}

          if ! kubectl get deployment -n kube-system aws-load-balancer-controller --ignore-not-found; then
            echo "AWS Load Balancer Controller not found, installing..."

            VPC_ID=$(aws eks describe-cluster \
              --name ${{ env.CLUSTER_NAME }} \
              --region ${{ env.AWS_REGION }} \
              --query "cluster.resourcesVpcConfig.vpcId" \
              --output text)

            helm repo add eks https://aws.github.io/eks-charts
            helm repo update
            helm install aws-load-balancer-controller eks/aws-load-balancer-controller -n kube-system \
              --set clusterName=${{ env.CLUSTER_NAME }} \
              --set serviceAccount.create=false \
              --set serviceAccount.name=aws-load-balancer-controller \
              --set region=${{ env.AWS_REGION }} \
              --set vpcId=$VPC_ID

            echo "Sleeping for 90 seconds to allow webhook to become ready..."
            sleep 90
          else
            echo "AWS Load Balancer Controller already installed. Skipping install step."
          fi
          kubectl apply -f ingress.yml

      - name: Clean up workspace
        if: always()
        run: |
          echo "Cleaning up workspace..."
          # This step is mostly for completeness; GitHub Actions runners clean up after themselves.
          # If you have specific files or directories to remove, add them here.

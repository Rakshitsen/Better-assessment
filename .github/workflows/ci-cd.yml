name: CI/CD Pipeline

on:
  push:
    branches:
      - test
  workflow_dispatch:
    inputs:
      RECREATE_CLUSTER:
        description: 'Recreate EKS cluster on each run'
        required: false
        default: false
        type: boolean

env:
  VENV: "myenv"
  USER_NAME: "rakshitsen"
  IMAGE_NAME: "better-assess-image"
  AWS_REGION: "ap-south-1"
  CLUSTER_NAME: "demo-cluster"

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    permissions:
      id-token: write # Required for OIDC authentication with AWS
      contents: read # Required to checkout code

    steps:
      - name: Checkout SCM
        uses: actions/checkout@v4
        with:
          repository: 'Rakshitsen/Better-assessment.git'
          ref: 'test'

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python3 -m venv ${{ env.VENV }}
          . ${{ env.VENV }}/bin/activate
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Unit test
        run: |
          . ${{ env.VENV }}/bin/activate
          pytest

      - name: Linting
        run: |
          . ${{ env.VENV }}/bin/activate
          flake8 .
        continue-on-error: true # Allow pipeline to continue even if linting issues are found

      - name: Build Docker image
        run: |
          docker build -t ${{ env.USER_NAME }}/${{ env.IMAGE_NAME }}:${{ github.run_number }} .

      - name: Security Scan (Trivy)
        run: |
          docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
          aquasec/trivy image ${{ env.USER_NAME }}/${{ env.IMAGE_NAME }}:${{ github.run_number }}

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Push Docker image
        run: |
          docker push ${{ env.USER_NAME }}/${{ env.IMAGE_NAME }}:${{ github.run_number }}

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/GitHubActionsRole # Replace with your IAM role ARN
          aws-region: ${{ env.AWS_REGION }}

      - name: Create EKS Cluster (Conditioned)
        if: github.event.inputs.RECREATE_CLUSTER == 'true'
        run: |
          eksctl create cluster \
            --name ${{ env.CLUSTER_NAME }} \
            --region ${{ env.AWS_REGION }} \
            --nodegroup-name ng1 \
            --node-type t3.medium \
            --nodes 2
          eksctl utils associate-iam-oidc-provider --cluster ${{ env.CLUSTER_NAME }} --approve --region ${{ env.AWS_REGION }}

          curl -O https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.11.0/docs/install/iam_policy.json
          aws iam create-policy \
          --policy-name AWSLoadBalancerControllerIAMPolicy \
          --policy-document file://iam_policy.json

          eksctl create iamserviceaccount \
          --cluster ${{ env.CLUSTER_NAME }} \
          --namespace kube-system \
          --name aws-load-balancer-controller \
          --role-name AmazonEKSLoadBalancerControllerRole \
          --attach-policy-arn arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:policy/AWSLoadBalancerControllerIAMPolicy \
          --approve \
          --region ${{ env.AWS_REGION }}

      - name: Deploy on K8S using EKS
        run: |
          aws eks --region ${{ env.AWS_REGION }} update-kubeconfig --name ${{ env.CLUSTER_NAME }}
          kubectl apply -f namespace.yml
          sed -i "s|image:latest|${{ env.USER_NAME }}/${{ env.IMAGE_NAME }}:${{ github.run_number }}|g" deployment.yml
          kubectl apply -f deployment.yml
          kubectl apply -f service.yml

      - name: Ingress and Ingress Controller
        run: |
          aws eks --region ${{ env.AWS_REGION }} update-kubeconfig --name ${{ env.CLUSTER_NAME }}
          if ! kubectl get deployment -n kube-system aws-load-balancer-controller --ignore-not-found; then
            echo "AWS Load Balancer Controller not found, installing..."

            VPC_ID=$(aws eks describe-cluster \
                --name ${{ env.CLUSTER_NAME }} \
                --region ${{ env.AWS_REGION }} \
                --query "cluster.resourcesVpcConfig.vpcId" \
                --output text)

            helm repo add eks https://aws.github.io/eks-charts
            helm repo update
            helm install aws-load-balancer-controller eks/aws-load-balancer-controller -n kube-system \
                --set clusterName=${{ env.CLUSTER_NAME }} \
                --set serviceAccount.create=false \
                --set serviceAccount.name=aws-load-balancer-controller \
                --set region=${{ env.AWS_REGION }} \
                --set vpcId=$VPC_ID

            echo "Sleeping for 90 seconds to allow webhook to become ready..."
            sleep 90
          else
            echo "AWS Load Balancer Controller already installed. Skipping install step."
          fi
          kubectl apply -f ingress.yml
